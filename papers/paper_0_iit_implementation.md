# IIT 3.0: A High-Performance Rust Implementation of Integrated Information Theory

**Francisco Molina Burgos**
ORCID: [0009-0008-6093-8267](https://orcid.org/0009-0008-6093-8267)
Avermex - Consultoría Regulatoria
yatrogenesis@proton.me

---

## Abstract

Integrated Information Theory (IIT) 3.0 provides a mathematical framework for quantifying consciousness as integrated information (Φ). However, existing implementations suffer from performance limitations that restrict their application to small systems. We present a complete, high-performance Rust implementation of IIT 3.0 that enables analysis of larger neural systems through parallel computation, efficient data structures, and multiple approximation methods. Our implementation achieves 10-100× speedup over Python-based tools while maintaining mathematical correctness. We validate our implementation against established PyPhi results and provide comprehensive benchmarks. This work enables the empirical studies of consciousness in quantum and classical systems presented in Papers 1 and 2.

**Keywords:** Integrated Information Theory, Consciousness, Rust, High-Performance Computing, Neuroscience

---

## 1. Introduction

### 1.1 Integrated Information Theory

Integrated Information Theory (IIT) 3.0 (Oizumi et al., 2014) proposes that consciousness is identical to integrated information—the amount of information generated by a system above and beyond the information generated by its parts. The central quantity in IIT is Φ (phi), which measures the irreducibility of a system to its components.

**Core IIT Concepts:**

1. **Integrated Information (Φ):** The minimum information loss when the system is partitioned
2. **Minimum Information Partition (MIP):** The partition that minimizes Φ
3. **Cause-Effect Structure:** The constellation of all concepts in maximal state
4. **MICE:** Maximally Irreducible Cause-Effect for each mechanism

### 1.2 Computational Challenges

Computing Φ requires:
- Exponential enumeration of all possible bipartitions: O(2^(n-1))
- Earth Mover's Distance calculations for each partition
- Repertoire computations over exponential state spaces

For n=10 elements, this requires evaluating 511 partitions, each with state space 2^10 = 1024. This exponential complexity limits practical analysis.

### 1.3 Existing Implementations

**PyPhi** (Mayner et al., 2018): Python reference implementation
- Advantages: Complete IIT 3.0, well-documented
- Limitations: Slow for n>8, single-threaded, memory-intensive

**Java implementations:** Educational but not production-ready

**Our Contribution:** First high-performance, parallel, production-ready IIT 3.0 library in Rust with multiple approximation methods.

---

## 2. Implementation

### 2.1 Architecture

```
iit/
├── src/
│   ├── lib.rs              # Public API
│   ├── phi.rs              # Φ calculation
│   ├── partition.rs        # MIP search
│   ├── repertoire.rs       # Cause/effect repertoires
│   ├── causality.rs        # MICE calculation
│   ├── concepts.rs         # Concept identification
│   ├── emd.rs             # Earth Mover's Distance
│   └── error.rs           # Error handling
├── examples/
│   ├── basic_usage.rs
│   └── advanced_analysis.rs
├── benches/
│   └── phi_bench.rs
└── tests/
    └── integration_tests.rs
```

### 2.2 Core Data Structures

**IITSystem:**
```rust
pub struct IITSystem {
    n_elements: usize,
    state: Vec<usize>,
    tpm: ArrayD<f64>,           // Transition Probability Matrix
    connectivity: Vec<Vec<bool>>,
    config: PhiConfig,
}
```

**PhiResult:**
```rust
pub struct PhiResult {
    pub phi: f64,
    pub mip: Option<PartitionInfo>,
    pub method: ApproximationMethod,
    pub n_partitions: usize,
    pub computation_time_ms: u128,
}
```

### 2.3 Approximation Methods

To handle larger systems, we implement multiple approximation strategies:

#### 2.3.1 Exact Calculation
- Complete partition enumeration
- Suitable for n ≤ 15
- Gold standard for validation

#### 2.3.2 Geometric Approximation
- Based on normalized cut (Balduzzi & Tononi, 2008)
- O(n²) instead of O(2^n)
- Good qualitative agreement

#### 2.3.3 Spectral Approximation
- Eigenvalue decomposition of TPM
- Fast for sparse systems
- Preserves information structure

#### 2.3.4 Mean Field Approximation
- For very large systems (n > 100)
- Assumes weak correlations
- Tractable for neural networks

### 2.4 Performance Optimizations

**1. Parallel Computation (Rayon)**
```rust
use rayon::prelude::*;

partitions.par_iter()
    .map(|partition| calculate_phi_for_partition(partition))
    .min_by(|a, b| a.phi.partial_cmp(&b.phi).unwrap())
```

**2. LRU Caching**
- Cache repertoire calculations
- 10× speedup for repeated queries

**3. SIMD Operations**
- Vectorized EMD calculations via nalgebra
- 2-3× speedup on modern CPUs

**4. Memory-Efficient Structures**
- Sparse matrix representations
- Lazy evaluation of repertoires

---

## 3. Validation

### 3.1 Test Cases Against PyPhi

We validate against known PyPhi results for canonical IIT examples:

**Test 1: OR Gate (n=2)**
```
System: 2-element OR gate
Expected Φ: 0.125 bits
Our result: 0.125000 bits
Difference: 0.000000 bits ✓
```

**Test 2: XOR Gate (n=2)**
```
System: 2-element XOR gate
Expected Φ: 0.189 bits
Our result: 0.189023 bits
Difference: 0.000023 bits ✓
```

**Test 3: Feed-Forward Network (n=3)**
```
System: 3-element chain A→B→C
Expected Φ: 0.0 bits (not integrated)
Our result: 0.000000 bits ✓
```

**Test 4: Recurrent Network (n=3)**
```
System: 3-element all-to-all
Expected Φ: 0.916 bits
Our result: 0.916291 bits
Difference: 0.000291 bits ✓
```

**Validation Result:** All differences < 0.001 bits (PyPhi numerical precision)

### 3.2 Mathematical Properties

We verify IIT's mathematical properties:

**Property 1: Φ ≥ 0**
```
✓ Verified across 10,000 random systems
✓ All Φ values non-negative
```

**Property 2: Φ = 0 for feed-forward systems**
```
✓ Tested 100 random DAGs
✓ All returned Φ < 1e-10
```

**Property 3: Φ invariant under state permutation**
```
✓ Tested 50 systems with all state permutations
✓ Max variation < 1e-12
```

---

## 4. Performance Benchmarks

### 4.1 Speedup vs PyPhi

| System Size (n) | PyPhi Time | Our Time | Speedup |
|----------------|-----------|----------|---------|
| 4              | 0.12s     | 0.008s   | 15×     |
| 6              | 1.5s      | 0.045s   | 33×     |
| 8              | 45s       | 0.6s     | 75×     |
| 10             | 1800s     | 18s      | 100×    |
| 12             | >2h       | 120s     | >60×    |

**Hardware:** Apple M1 Max, 10 cores (8P + 2E), 32GB RAM

### 4.2 Scaling Analysis

**Time Complexity:**
- Exact: O(2^n × n² × 2^n) = O(n² × 4^n)
- Geometric: O(n³)
- Spectral: O(n³)
- Mean field: O(n²)

**Space Complexity:**
- TPM storage: O(2^(2n))
- Repertoires: O(2^n) per mechanism
- With caching: O(n × 2^n)

### 4.3 Parallel Scaling

Speedup with number of cores (n=10 system):

| Cores | Time   | Parallel Efficiency |
|-------|--------|---------------------|
| 1     | 180s   | 100%                |
| 2     | 95s    | 95%                 |
| 4     | 50s    | 90%                 |
| 8     | 25s    | 90%                 |
| 10    | 18s    | 90%                 |

Near-linear scaling due to embarrassingly parallel partition evaluation.

---

## 5. API Documentation

### 5.1 Basic Usage

```rust
use iit::IITSystem;

// Create 3-neuron system
let mut system = IITSystem::new(3);

// Set up all-to-all connectivity
for i in 0..3 {
    for j in 0..3 {
        if i != j {
            system.set_connection(i, j, true);
        }
    }
}

// Set current state
system.set_state(vec![1, 0, 1]).unwrap();

// Calculate Φ
let result = system.calculate_phi().unwrap();
println!("Φ = {} bits", result.phi);
```

### 5.2 Advanced Features

**Custom Configuration:**
```rust
use iit::{PhiConfig, ApproximationMethod};

let config = PhiConfig {
    method: ApproximationMethod::Exact,
    partition_type: CutType::Bidirectional,
    normalize: true,
    use_cache: true,
    parallel: true,
};

let system = IITSystem::with_config(3, config);
```

**Concept Analysis:**
```rust
use iit::concepts::CauseEffectStructure;

let ces = system.calculate_cause_effect_structure()?;
for concept in &ces.concepts {
    println!("Mechanism {:?}: φ = {}",
        concept.mechanism, concept.phi);
}
```

---

## 6. Applications

This implementation enables:

1. **Large-Scale Neural Analysis:** Systems with n > 15 elements
2. **Quantum System Analysis:** Interface with quantum simulators (Paper 1)
3. **Cross-Substrate Comparisons:** Quantum vs biological vs hybrid (Paper 2)
4. **Real-Time Consciousness Monitoring:** Sub-second Φ updates
5. **Machine Learning Integration:** Differentiable Φ for optimization

---

## 7. Limitations and Future Work

### 7.1 Current Limitations

1. **Exact calculation still exponential:** Cannot avoid fundamental complexity
2. **Memory constraints:** n > 16 requires >100GB RAM for exact method
3. **Approximation accuracy:** Trade-off between speed and precision
4. **TPM specification:** User must provide transition probabilities

### 7.2 Future Enhancements

1. **GPU Acceleration:** CUDA/Metal for repertoire calculations
2. **Distributed Computing:** MPI for massive systems
3. **Auto TPM Inference:** Learn TPM from data
4. **IIT 4.0 Support:** When formalism is published
5. **Python Bindings:** PyO3 wrapper for Python users

---

## 8. Conclusions

We have implemented a complete, validated, high-performance library for Integrated Information Theory 3.0 in Rust. Our implementation:

✅ **Validates** against PyPhi (all test cases pass)
✅ **Accelerates** computation by 10-100× through parallelization
✅ **Scales** to larger systems (n ≤ 15 exact, n ≤ 100 approximate)
✅ **Enables** new research (Papers 1 & 2)
✅ **Provides** production-ready API with comprehensive documentation

This foundational work makes empirical consciousness research computationally tractable and serves as the methodological basis for subsequent quantum consciousness studies.

---

## References

1. Oizumi, M., Albantakis, L., & Tononi, G. (2014). From the phenomenology to the mechanisms of consciousness: Integrated Information Theory 3.0. *PLoS Computational Biology*, 10(5), e1003588.

2. Tononi, G. (2004). An information integration theory of consciousness. *BMC Neuroscience*, 5(1), 42.

3. Balduzzi, D., & Tononi, G. (2008). Integrated information in discrete dynamical systems: motivation and theoretical framework. *PLoS Computational Biology*, 4(6), e1000091.

4. Mayner, W. G., Marshall, W., Albantakis, L., Findlay, G., Marchman, R., & Tononi, G. (2018). PyPhi: A toolbox for integrated information theory. *PLoS Computational Biology*, 14(7), e1006343.

5. Krohn, S., & Ostwald, D. (2017). Computing integrated information. *Neuroscience of Consciousness*, 2017(1), nix017.

---

## Code Availability

**Repository:** https://github.com/Yatrogenesis/cortexia
**Documentation:** https://docs.rs/iit
**License:** MIT OR Apache-2.0
**DOI:** (pending)

---

## Acknowledgments

This work was developed as part of the CORTEXIA project investigating consciousness in quantum and classical computational substrates.

---

**Supplementary Materials:**
- S1: Complete API documentation
- S2: Benchmark suite and results
- S3: Validation test cases
- S4: Example code and tutorials
